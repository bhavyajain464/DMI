{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepOneClassClassification_letter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlBjGaTAoY4b"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/letter-recognition.data\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FsjqKAJJrriJ",
        "outputId": "ba877168-a4b3-44b4-bda9-0976f66ba15f"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>D</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>N</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>G</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19995</th>\n",
              "      <td>D</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19996</th>\n",
              "      <td>C</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19997</th>\n",
              "      <td>T</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19998</th>\n",
              "      <td>S</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999</th>\n",
              "      <td>A</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20000 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Label  1   2  3  4  5   6   7  8  9  10  11  12  13  14  15  16\n",
              "0         T  2   8  3  5  1   8  13  0  6   6  10   8   0   8   0   8\n",
              "1         I  5  12  3  7  2  10   5  5  4  13   3   9   2   8   4  10\n",
              "2         D  4  11  6  8  6  10   6  2  6  10   3   7   3   7   3   9\n",
              "3         N  7  11  6  6  3   5   9  4  6   4   4  10   6  10   2   8\n",
              "4         G  2   1  3  1  1   8   6  6  6   6   5   9   1   7   5  10\n",
              "...     ... ..  .. .. .. ..  ..  .. .. ..  ..  ..  ..  ..  ..  ..  ..\n",
              "19995     D  2   2  3  3  2   7   7  7  6   6   6   4   2   8   3   7\n",
              "19996     C  7  10  8  8  4   4   8  6  9  12   9  13   2   9   3   7\n",
              "19997     T  6   9  6  7  5   6  11  3  7  11   9   5   2  12   2   4\n",
              "19998     S  2   3  4  2  1   8   7  2  6  10   6   8   1   9   5   8\n",
              "19999     A  4   9  6  6  2   9   5  3  1   8   1   8   2   7   2   8\n",
              "\n",
              "[20000 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "w9nerkOkru03",
        "outputId": "0b5938b5-db98-47b1-d1d0-150ab2911756"
      },
      "source": [
        "data['Label'].hist(bins=120)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3404fafc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9k9cZAYcsEf"
      },
      "source": [
        "train_data = data.sample(frac=0.7)\n",
        "test_data = data.drop(train_data.index)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9X5IUOrqdkG-"
      },
      "source": [
        "import numpy as np\n",
        "def label_data(label):\n",
        "  labels = np.array(train_data['Label'].unique())\n",
        "  df = []\n",
        "  for l in labels:\n",
        "    if(l==label):\n",
        "      df.append(train_data[train_data['Label']==l])\n",
        "    else:\n",
        "      df.append(train_data[train_data['Label']==l].sample(frac=0.04))\n",
        "  return pd.concat(df)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OUloQ0nUqJK"
      },
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "OCSVM_for_label = {}\n",
        "int_to_letter = {}\n",
        "for i,l in enumerate(np.array(train_data['Label'].unique())):\n",
        "  int_to_letter[i]=l\n",
        "  data_label = label_data(l)\n",
        "  data_label['Label'].replace()\n",
        "  clf = OneClassSVM(gamma='auto',kernel='rbf').fit(data_label.drop('Label',axis=1))\n",
        "  OCSVM_for_label[l]=clf"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnMDTzi5fl7s"
      },
      "source": [
        "predictions = []\n",
        "for let in OCSVM_for_label:\n",
        "  predictions.append(OCSVM_for_label[let].decision_function(test_data.drop('Label',axis=1)))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE8fGnWuf6Ue"
      },
      "source": [
        "predictions = np.array(predictions).T"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTAIwiNJhTOc"
      },
      "source": [
        "ans = []\n",
        "for i,pred in enumerate(predictions):\n",
        "  ans.append(int_to_letter[pred.argmax()])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4Z8EGL9h-ty",
        "outputId": "d88c57fe-03fb-4360-9eaf-bc53f8b443f5"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_data['Label'], ans))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.96      0.96      0.96       227\n",
            "           B       0.88      0.65      0.75       260\n",
            "           C       0.75      0.93      0.83       212\n",
            "           D       0.77      0.81      0.79       245\n",
            "           E       0.83      0.73      0.77       216\n",
            "           F       0.88      0.76      0.82       236\n",
            "           G       0.77      0.56      0.65       235\n",
            "           H       0.80      0.57      0.67       235\n",
            "           I       0.82      0.92      0.87       199\n",
            "           J       0.88      0.97      0.92       232\n",
            "           K       0.76      0.88      0.82       217\n",
            "           L       0.93      0.93      0.93       226\n",
            "           M       0.76      0.99      0.86       232\n",
            "           N       0.86      0.91      0.89       253\n",
            "           O       0.68      0.75      0.71       217\n",
            "           P       0.88      0.90      0.89       253\n",
            "           Q       0.83      0.89      0.86       249\n",
            "           R       0.86      0.73      0.79       226\n",
            "           S       0.79      0.79      0.79       219\n",
            "           T       0.85      0.85      0.85       239\n",
            "           U       0.95      0.93      0.94       239\n",
            "           V       0.91      0.90      0.90       220\n",
            "           W       0.91      0.91      0.91       236\n",
            "           X       0.80      0.68      0.73       234\n",
            "           Y       0.86      0.97      0.91       231\n",
            "           Z       0.82      0.91      0.86       212\n",
            "\n",
            "    accuracy                           0.84      6000\n",
            "   macro avg       0.84      0.84      0.83      6000\n",
            "weighted avg       0.84      0.84      0.83      6000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izQjgBrY-UZY"
      },
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "OCSVM_for_label = {}\n",
        "int_to_letter = {}\n",
        "for i,l in enumerate(np.array(train_data['Label'].unique())):\n",
        "  int_to_letter[i]=l\n",
        "  data_label = label_data(l)\n",
        "  data_label['Label'].replace()\n",
        "  clf = OneClassSVM(gamma='auto',kernel='poly').fit(data_label.drop('Label',axis=1))\n",
        "  OCSVM_for_label[l]=clf"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwXPCUcj-UZb"
      },
      "source": [
        "predictions = []\n",
        "for let in OCSVM_for_label:\n",
        "  predictions.append(OCSVM_for_label[let].decision_function(test_data.drop('Label',axis=1)))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4aoVpgt-UZf"
      },
      "source": [
        "predictions = np.array(predictions).T"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w-CnBzF-UZi"
      },
      "source": [
        "ans = []\n",
        "for i,pred in enumerate(predictions):\n",
        "  ans.append(int_to_letter[pred.argmax()])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIwyA1cd-UZj",
        "outputId": "ea40c891-427f-44ee-ef0a-58181cce6984"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_data['Label'], ans))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.06      0.47      0.11       227\n",
            "           B       0.00      0.00      0.00       260\n",
            "           C       0.00      0.00      0.00       212\n",
            "           D       0.05      0.08      0.06       245\n",
            "           E       0.00      0.00      0.00       216\n",
            "           F       0.24      0.09      0.13       236\n",
            "           G       0.00      0.00      0.00       235\n",
            "           H       0.00      0.00      0.00       235\n",
            "           I       0.05      0.17      0.08       199\n",
            "           J       0.75      0.01      0.03       232\n",
            "           K       0.00      0.00      0.00       217\n",
            "           L       0.07      0.75      0.13       226\n",
            "           M       0.26      0.14      0.18       232\n",
            "           N       0.18      0.07      0.10       253\n",
            "           O       0.00      0.00      0.00       217\n",
            "           P       0.87      0.11      0.19       253\n",
            "           Q       0.80      0.03      0.06       249\n",
            "           R       0.18      0.01      0.02       226\n",
            "           S       0.15      0.04      0.06       219\n",
            "           T       0.00      0.00      0.00       239\n",
            "           U       0.32      0.21      0.26       239\n",
            "           V       0.50      0.00      0.01       220\n",
            "           W       0.89      0.11      0.19       236\n",
            "           X       0.13      0.08      0.10       234\n",
            "           Y       0.28      0.03      0.05       231\n",
            "           Z       0.00      0.00      0.00       212\n",
            "\n",
            "    accuracy                           0.09      6000\n",
            "   macro avg       0.22      0.09      0.07      6000\n",
            "weighted avg       0.23      0.09      0.07      6000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQG_RbrZ-VAW"
      },
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "OCSVM_for_label = {}\n",
        "int_to_letter = {}\n",
        "for i,l in enumerate(np.array(train_data['Label'].unique())):\n",
        "  int_to_letter[i]=l\n",
        "  data_label = label_data(l)\n",
        "  data_label['Label'].replace()\n",
        "  clf = OneClassSVM(gamma='auto',kernel='linear').fit(data_label.drop('Label',axis=1))\n",
        "  OCSVM_for_label[l]=clf"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfRTT38G-VAb"
      },
      "source": [
        "predictions = []\n",
        "for let in OCSVM_for_label:\n",
        "  predictions.append(OCSVM_for_label[let].decision_function(test_data.drop('Label',axis=1)))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugb8h0T4-VAd"
      },
      "source": [
        "predictions = np.array(predictions).T"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4PTeOae-VAf"
      },
      "source": [
        "ans = []\n",
        "for i,pred in enumerate(predictions):\n",
        "  ans.append(int_to_letter[pred.argmax()])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Icus6WJ--VAg",
        "outputId": "a1057ec8-7fc8-4a07-c042-ce7e3aca973d"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_data['Label'], ans))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.07      0.90      0.12       227\n",
            "           B       0.00      0.00      0.00       260\n",
            "           C       0.00      0.00      0.00       212\n",
            "           D       0.00      0.00      0.00       245\n",
            "           E       0.00      0.00      0.00       216\n",
            "           F       0.44      0.02      0.03       236\n",
            "           G       0.00      0.00      0.00       235\n",
            "           H       0.00      0.00      0.00       235\n",
            "           I       0.05      0.19      0.08       199\n",
            "           J       0.00      0.00      0.00       232\n",
            "           K       0.00      0.00      0.00       217\n",
            "           L       0.08      0.77      0.15       226\n",
            "           M       0.80      0.03      0.07       232\n",
            "           N       0.17      0.00      0.01       253\n",
            "           O       0.00      0.00      0.00       217\n",
            "           P       1.00      0.04      0.08       253\n",
            "           Q       0.00      0.00      0.00       249\n",
            "           R       0.00      0.00      0.00       226\n",
            "           S       0.00      0.00      0.00       219\n",
            "           T       0.00      0.00      0.00       239\n",
            "           U       0.75      0.01      0.02       239\n",
            "           V       0.00      0.00      0.00       220\n",
            "           W       0.00      0.00      0.00       236\n",
            "           X       0.00      0.00      0.00       234\n",
            "           Y       0.00      0.00      0.00       231\n",
            "           Z       0.00      0.00      0.00       212\n",
            "\n",
            "    accuracy                           0.07      6000\n",
            "   macro avg       0.13      0.08      0.02      6000\n",
            "weighted avg       0.13      0.07      0.02      6000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEJtF32_-Veu"
      },
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "OCSVM_for_label = {}\n",
        "int_to_letter = {}\n",
        "for i,l in enumerate(np.array(train_data['Label'].unique())):\n",
        "  int_to_letter[i]=l\n",
        "  data_label = label_data(l)\n",
        "  data_label['Label'].replace()\n",
        "  clf = OneClassSVM(gamma='auto',kernel='sigmoid').fit(data_label.drop('Label',axis=1))\n",
        "  OCSVM_for_label[l]=clf"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_jNuFjs-Vey"
      },
      "source": [
        "predictions = []\n",
        "for let in OCSVM_for_label:\n",
        "  predictions.append(OCSVM_for_label[let].decision_function(test_data.drop('Label',axis=1)))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26-CG6t2-Vez"
      },
      "source": [
        "predictions = np.array(predictions).T"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ63lMF0-Ve0"
      },
      "source": [
        "ans = []\n",
        "for i,pred in enumerate(predictions):\n",
        "  ans.append(int_to_letter[pred.argmax()])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RmJU5RY-Ve0",
        "outputId": "8316e4e6-769d-4e1f-e503-6f53a3e157e1"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_data['Label'], ans))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.00      0.00      0.00       227\n",
            "           B       0.00      0.00      0.00       260\n",
            "           C       0.00      0.00      0.00       212\n",
            "           D       0.00      0.00      0.00       245\n",
            "           E       0.00      0.00      0.00       216\n",
            "           F       0.00      0.00      0.00       236\n",
            "           G       0.00      0.00      0.00       235\n",
            "           H       0.00      0.00      0.00       235\n",
            "           I       0.00      0.00      0.00       199\n",
            "           J       0.00      0.00      0.00       232\n",
            "           K       0.00      0.00      0.00       217\n",
            "           L       0.00      0.00      0.00       226\n",
            "           M       0.00      0.00      0.00       232\n",
            "           N       0.00      0.00      0.00       253\n",
            "           O       0.00      0.00      0.00       217\n",
            "           P       0.00      0.00      0.00       253\n",
            "           Q       0.00      0.00      0.00       249\n",
            "           R       0.00      0.00      0.00       226\n",
            "           S       0.00      0.00      0.00       219\n",
            "           T       0.00      0.00      0.00       239\n",
            "           U       0.04      1.00      0.08       239\n",
            "           V       0.00      0.00      0.00       220\n",
            "           W       0.00      0.00      0.00       236\n",
            "           X       0.00      0.00      0.00       234\n",
            "           Y       0.00      0.00      0.00       231\n",
            "           Z       0.00      0.00      0.00       212\n",
            "\n",
            "    accuracy                           0.04      6000\n",
            "   macro avg       0.00      0.04      0.00      6000\n",
            "weighted avg       0.00      0.04      0.00      6000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whh-Vt3nMLb0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}